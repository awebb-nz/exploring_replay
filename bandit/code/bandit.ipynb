{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4986d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, pickle\n",
    "from belief_tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b66ed72",
   "metadata": {},
   "source": [
    "### Initialise the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa57b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(q_values, temp=None, policy_type='softmax'):\n",
    "\n",
    "    '''\n",
    "    ----\n",
    "    Agent's policy\n",
    "\n",
    "    q_values -- q values at the current state\n",
    "    temp     -- inverse temperature\n",
    "    type     -- softmax / greeedy\n",
    "    ----\n",
    "    '''\n",
    "\n",
    "    if np.all(q_values == 0):\n",
    "        return np.array([0.5, 0.5])\n",
    "\n",
    "    if temp:\n",
    "        t = temp\n",
    "    else:\n",
    "        t = 1\n",
    "        \n",
    "    if policy_type == 'softmax':\n",
    "        return np.exp(q_values*t)/np.sum(np.exp(q_values*t))\n",
    "    elif policy_type == 'greedy':\n",
    "        return np.array(q_values >= q_values.max()).astype(int)\n",
    "    else:\n",
    "        raise KeyError('Unknown policy type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f56304",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([\n",
    "    [29, 1],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "gamma = 0.9\n",
    "xi    = 0.0\n",
    "\n",
    "Q = np.zeros(2)\n",
    "\n",
    "tree = Tree(M, Q, 1, 'greedy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb9e80",
   "metadata": {},
   "source": [
    "### Full Bayesian updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e27056",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 3\n",
    "tree.root_q_values = Q\n",
    "tree.build_tree(horizon)\n",
    "tree.full_updates(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ba4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qval_tree = tree.qval_tree\n",
    "qval_tree[0][(0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96108735",
   "metadata": {},
   "source": [
    "### Replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13547ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 3\n",
    "tree.root_q_values = Q\n",
    "tree.build_tree(horizon)\n",
    "qval_history, need_history, replays = tree.replay_updates(gamma, xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd449612",
   "metadata": {},
   "outputs": [],
   "source": [
    "qval_tree = tree.qval_tree\n",
    "qval_tree[0][(0, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c33603",
   "metadata": {},
   "source": [
    "### Generate replay tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tex_tree import generate_big_tex_tree\n",
    "\n",
    "save_folder = '/home/georgy/Documents/Dayan_lab/PhD/bandits/Data/example_tree/seq/'\n",
    "if os.path.exists(save_folder):\n",
    "    shutil.rmtree(save_folder)\n",
    "    os.mkdir(save_folder)\n",
    "else:\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "for idx, rep in enumerate(replays):\n",
    "    these_replays = replays[:idx+1]\n",
    "    save_path = os.path.join(save_folder, 'tex_tree_%u.tex'%idx)\n",
    "    generate_big_tex_tree(horizon, these_replays, qval_history[idx], need_history[idx], save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c62fc",
   "metadata": {},
   "source": [
    "### Distribution updates asymmetry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2702e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.001, 1, 100)\n",
    "\n",
    "a1b, b1b = np.array([7, 4])\n",
    "rv1b = beta(a1b, b1b)  \n",
    "\n",
    "a1a, b1a = np.array([2, 4])\n",
    "rv1a = beta(a1a, b1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6), dpi=100)\n",
    "\n",
    "plt.plot(x, rv1b.pdf(x), label='Arm 1')\n",
    "plt.plot(x, rv1a.pdf(x), label='Arm 2')\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0,)\n",
    "\n",
    "plt.xlabel(r'$p$', fontsize=17)\n",
    "plt.ylabel('PDF', fontsize=17)\n",
    "plt.legend(prop={'size':13})\n",
    "# plt.savefig('/home/georgy/Documents/Dayan_lab/PhD/bandits/Data/betas.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a2119",
   "metadata": {},
   "source": [
    "### Number of replays until convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = '/home/georgy/Documents/Dayan_lab/PhD/bandits/bandit/data/convergence/num_replays/'\n",
    "\n",
    "# vary these parameters\n",
    "alphas_0 = np.arange(1, 40)\n",
    "betas_0  = np.arange(1, 40)\n",
    "\n",
    "# constant parameters\n",
    "alpha_1 = 1\n",
    "beta_1  = 1\n",
    "\n",
    "gamma   = 0.9\n",
    "temp    = 1\n",
    "xi      = 0.1\n",
    "\n",
    "save_figures_path = os.path.join(save_folder, 'temp%u'%temp)\n",
    "save_data_path    = os.path.join(save_folder, 'data', 'temp%u'%temp)\n",
    "\n",
    "if not os.path.isdir(save_figures_path):\n",
    "    os.makedirs(save_figures_path)\n",
    "    os.makedirs(save_data_path)\n",
    "\n",
    "for horizon in [3, 4, 5]:\n",
    "\n",
    "    R_true = np.full((len(alphas_0), len(betas_0)), np.nan)\n",
    "    R      = np.full((len(alphas_0), len(betas_0)), np.nan)\n",
    "    N      = np.full((len(alphas_0), len(betas_0)), np.nan)\n",
    "\n",
    "    for alpha_0 in alphas_0:\n",
    "        for beta_0 in betas_0:\n",
    "            \n",
    "            # prior belie at the root\n",
    "            M = np.array([\n",
    "                [alpha_0, beta_0],\n",
    "                [alpha_1, beta_1],\n",
    "            ])\n",
    "\n",
    "            # MF Q values at the root\n",
    "            Q    = np.zeros(2)\n",
    "\n",
    "            # initialise the agent\n",
    "            tree = Tree(M, Q, temp, 'softmax')\n",
    "\n",
    "            # build the tree\n",
    "            tree.build_tree(horizon)\n",
    "            \n",
    "            # do full bayesian updates\n",
    "            tree.full_updates(gamma)\n",
    "            qval_tree = tree.qval_tree\n",
    "            qvals     = qval_tree[0][(0, 0, 0)]\n",
    "            print(r'$\\alpha_0=%u, \\beta_0=%u$'%(alpha_0, beta_0))\n",
    "            v_full = np.max(qvals)\n",
    "            \n",
    "            # do replay\n",
    "            tree.root_q_values = np.zeros(2)\n",
    "            qval_history, need_history, replays = tree.replay_updates(gamma, xi)\n",
    "            qval_tree = qval_history[-1]\n",
    "            qvals     = qval_tree[0][(0, 0, 0)]\n",
    "            v_replay  = np.dot(policy(qvals, temp=temp), qvals)\n",
    "\n",
    "            R_true[alpha_0-alphas_0[0], beta_0-betas_0[0]] = v_full\n",
    "            R[alpha_0-alphas_0[0], beta_0-betas_0[0]]      = v_replay\n",
    "            N[alpha_0-alphas_0[0], beta_0-betas_0[0]]      = len(qval_history) - 1\n",
    "\n",
    "    file_name = 'value_horizon%u_alpha%u_beta%u_xi%s_temp%u'%(horizon-1, alpha_1, beta_1, ''.join(str(xi).split('.')), temp)\n",
    "    np.save(os.path.join(save_data_path, file_name + '.npy'), R)\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=100, constrained_layout=True)\n",
    "    plt.pcolormesh(R, vmax=np.nanmax(R))\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('Root value', rotation=270, fontsize=14, labelpad=18)\n",
    "    plt.xlabel(r'$\\beta_0$', fontsize=14)\n",
    "    plt.xticks(range(R.shape[0]), range(1, R.shape[0]+1))\n",
    "    plt.ylabel(r'$\\alpha_0$', fontsize=14)\n",
    "    plt.yticks(range(R.shape[1]), range(1, R.shape[1]+1))\n",
    "    plt.title(r'$\\alpha_1=%u, \\beta_1=%u$'%(alpha_1, beta_1), fontsize=18)\n",
    "    plt.savefig(os.path.join(save_figures_path, file_name + '.png'))\n",
    "    plt.close()\n",
    "\n",
    "    diff      = R_true - R\n",
    "    file_name = 'value_diff_horizon%u_alpha%u_beta%u_xi%s_temp%u'%(horizon-1, alpha_1, beta_1, ''.join(str(xi).split('.')), temp)\n",
    "    np.save(os.path.join(save_data_path, file_name + '.npy'), diff)\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=100, constrained_layout=True)\n",
    "    plt.pcolormesh(diff, vmax=np.nanmax(diff))\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('delta root value', rotation=270, fontsize=14, labelpad=18)\n",
    "    plt.xlabel(r'$\\beta_0$', fontsize=14)\n",
    "    plt.xticks(range(R.shape[0]), range(1, R.shape[0]+1))\n",
    "    plt.ylabel(r'$\\alpha_0$', fontsize=14)\n",
    "    plt.yticks(range(R.shape[1]), range(1, R.shape[1]+1))\n",
    "    plt.title(r'$\\alpha_1=%u, \\beta_1=%u$'%(alpha_1, beta_1), fontsize=18)\n",
    "    plt.savefig(os.path.join(save_figures_path, file_name + '.png'))\n",
    "    plt.close()\n",
    "\n",
    "    file_name = 'num_horizon%u_alpha%u_beta%u_xi%s_temp%u'%(horizon-1, alpha_1, beta_1, ''.join(str(xi).split('.')), temp)\n",
    "    np.save(os.path.join(save_data_path, file_name + '.npy'), N)\n",
    "    fig = plt.figure(figsize=(10, 8), dpi=100, constrained_layout=True)\n",
    "    plt.pcolormesh(N, vmax=np.nanmax(N))\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('Number of replays', rotation=270, fontsize=14, labelpad=18)\n",
    "    plt.xlabel(r'$\\beta_0$', fontsize=14)\n",
    "    plt.xticks(range(R.shape[0]), range(1, R.shape[0]+1))\n",
    "    plt.ylabel(r'$\\alpha_0$', fontsize=14)\n",
    "    plt.yticks(range(R.shape[1]), range(1, R.shape[1]+1))\n",
    "    plt.title(r'$\\alpha_1=%u, \\beta_1=%u$'%(alpha_1, beta_1), fontsize=18)\n",
    "    plt.savefig(os.path.join(save_figures_path, file_name + '.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print('Done with horizon %u'%horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff04327",
   "metadata": {},
   "source": [
    "### Replay threshold and value convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01baa165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon 2\n",
      "Horizon 3\n",
      "Horizon 4\n",
      "Horizon 5\n",
      "0 [1.58333333 2.25833333 2.86583333 3.41258333]\n",
      "1 [1.58333333 2.25833333 2.86583333 3.41258333]\n",
      "2 [1.58333333 2.25833333 2.86583333 3.41258333]\n",
      "3 [1.58333333 2.25833333 2.86583333 3.41258333]\n"
     ]
    }
   ],
   "source": [
    "save_folder = '/home/georgy/Documents/Dayan_lab/PhD/bandits/rldm/figures/fig1/betas'\n",
    "\n",
    "# vary these parameters\n",
    "# xis       = np.append(0, np.logspace(np.log2(0.001), np.log2(1.0), 10, base=2))\n",
    "xis       = np.logspace(np.log2(0.001), np.log2(1.0), 11, base=2)\n",
    "horizons  = [2, 3, 4, 5]\n",
    "betas     = [1.5, 4]\n",
    "\n",
    "# constant parameters\n",
    "alpha_0 = 5\n",
    "beta_0  = 1\n",
    "alpha_1 = 2\n",
    "beta_1  = 4\n",
    "\n",
    "gamma   = 0.9\n",
    "\n",
    "# prior belie at the root\n",
    "M = np.array([\n",
    "    [alpha_0, beta_0],\n",
    "    [alpha_1, beta_1],\n",
    "], dtype=int)\n",
    "\n",
    "# MF Q values at the root\n",
    "Q    = np.zeros(2)\n",
    "\n",
    "# store results here\n",
    "P      = np.zeros((len(horizons), len(betas), len(xis)))\n",
    "R      = np.zeros((len(horizons), len(betas), len(xis)))\n",
    "nreps  = np.zeros((len(horizons), len(betas), len(xis)), dtype=int)\n",
    "R_true = np.zeros(len(horizons))\n",
    "\n",
    "for hidx, horizon in enumerate(horizons):\n",
    "            \n",
    "    # initialise the agent\n",
    "    tree = Tree(M, Q, 1, 'softmax')\n",
    "    tree.build_tree(horizon)\n",
    "    \n",
    "    # do full bayesian updates\n",
    "    tree.full_updates(gamma)\n",
    "    qval_tree    = tree.qval_tree\n",
    "    qvals        = qval_tree[0][(0, 0, 0)]\n",
    "    v_full       = np.max(qvals)\n",
    "    R_true[hidx] = v_full\n",
    "    \n",
    "    for bidx, beta in enumerate(betas):\n",
    "\n",
    "        # initialise the agent\n",
    "        tree = Tree(M, Q, beta, 'softmax')\n",
    "\n",
    "        for xidx, xi in enumerate(xis):\n",
    "\n",
    "            tree.build_tree(horizon)\n",
    "            # do replay\n",
    "            qval_history, need_history, replays = tree.replay_updates(gamma, xi)\n",
    "            qvals     = tree.qval_tree[0][(0, 0, 0)]\n",
    "            v_replay  = np.dot(policy(qvals, temp=beta), qvals)\n",
    "\n",
    "            eval_pol  = tree.evaluate_policy(tree.qval_tree)\n",
    "\n",
    "            P[hidx, bidx, xidx]     = eval_pol\n",
    "            R[hidx, bidx, xidx]     = v_replay\n",
    "            nreps[hidx, bidx, xidx] = len(replays)-1\n",
    "\n",
    "    print('Horizon %u'%horizon)\n",
    "\n",
    "fig, axes = plt.subplots(6, 2, figsize=(9, 18), dpi=100, constrained_layout=True, gridspec_kw={'height_ratios':[2, 2, 1, 2, 2, 1]})\n",
    "plt.suptitle('alpha0 = %u, beta0 = %u, alpha1 = %u, beta1 = %u'%(alpha_0, beta_0, alpha_1, beta_1), fontsize=14)\n",
    "\n",
    "for hidx, h in enumerate(horizons):\n",
    "\n",
    "    if (hidx == 0) or (hidx == 1): \n",
    "        axv = axes[0, hidx%2]\n",
    "        axp = axes[1, hidx%2]\n",
    "        axr = axes[2, hidx%2]\n",
    "    else:\n",
    "        axv = axes[3, hidx%2]\n",
    "        axp = axes[4, hidx%2]\n",
    "        axr = axes[5, hidx%2]\n",
    "\n",
    "    for bidx, beta in enumerate(betas): \n",
    "        \n",
    "        axv.plot(R[hidx, bidx, ::-1], label='Beta %.1f'%beta)\n",
    "        axv.scatter(range(len(xis)), R[hidx, bidx, ::-1])\n",
    "\n",
    "        axp.plot(P[hidx, bidx, ::-1], label='Beta %.1f'%beta)\n",
    "        axp.scatter(range(len(xis)), P[hidx, bidx, ::-1])\n",
    "        \n",
    "        axr.plot(nreps[hidx, bidx, ::-1], label='Beta %.1f'%beta)\n",
    "        axr.scatter(range(len(xis)), nreps[hidx, bidx, ::-1])\n",
    "\n",
    "        if bidx == (len(betas) - 1):\n",
    "\n",
    "            print(hidx, R_true)\n",
    "            axv.axhline(R_true[hidx], linestyle='--', color='k', alpha=0.7, label='Optimal value')\n",
    "            axp.axhline(R_true[hidx], linestyle='--', color='k', alpha=0.7, label='Optimal value')\n",
    "        \n",
    "            axv.legend(prop={'size': 13})\n",
    "            # axp.legend(prop={'size': 13})\n",
    "            # axr.legend(prop={'size': 13})\n",
    "\n",
    "            axv.set_ylabel('Root value', fontsize=17)\n",
    "            axv.set_ylim(0, np.max(R_true)+0.1)\n",
    "            axv.set_title('Horizon %u'%(h-1), fontsize=18)\n",
    "            axv.tick_params(axis='y', labelsize=13)\n",
    "\n",
    "            axp.set_ylabel('Policy value', fontsize=17)\n",
    "            axp.set_ylim(0, np.max(R_true)+0.1)\n",
    "            axp.tick_params(axis='y', labelsize=13)\n",
    "\n",
    "            axr.set_ylabel('Number of updates', fontsize=17)\n",
    "            axr.tick_params(axis='y', labelsize=13)\n",
    "            axr.set_ylim(0, np.nanmax(nreps)+6)\n",
    "\n",
    "            axr.set_xlabel(r'$\\xi$', fontsize=17)\n",
    "            axr.set_xticks(range(R.shape[2]), ['%.3f'%i for i in xis[::-1]], rotation=60, fontsize=13)\n",
    "\n",
    "            axv.set_xticks([])\n",
    "            axp.set_xticks([])\n",
    "\n",
    "file_name = 'alpha0%u_beta0%u_alpha1%u_beta1%u_complete'%(alpha_0, beta_0, alpha_1, beta_1)\n",
    "np.save(os.path.join(save_folder, 'data', file_name + '.npy'), R)\n",
    "plt.savefig(os.path.join(save_folder, file_name + '.svg'), transparent=True)\n",
    "plt.savefig(os.path.join(save_folder, file_name + '.png'))\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe1140",
   "metadata": {},
   "source": [
    "### Evaluated policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459ce333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save path\n",
    "root_folder = '/home/georgy/Documents/Dayan_lab/PhD/bandits'\n",
    "save_path   = os.path.join(root_folder, 'rldm/figures/fig1/trees/2')\n",
    "    \n",
    "with open(os.path.join(save_path, 'tree.pkl'), 'rb') as f:\n",
    "    tree = pickle.load(f)\n",
    "\n",
    "qval_history = np.load(os.path.join(save_path, 'qval_history.npy'), allow_pickle=True)\n",
    "\n",
    "root_values      = []\n",
    "for i in qval_history:\n",
    "    qval_tree    = i\n",
    "    root_values += [tree.evaluate_policy(i)]\n",
    "\n",
    "tree.full_updates(tree.gamma)\n",
    "qval_tree = tree.qval_tree\n",
    "qvals     = qval_tree[0][(0, 0, 0)]\n",
    "v_full    = np.max(qvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72a58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(root_values)\n",
    "plt.axhline(v_full, linestyle='--', color='k', alpha=0.7, label='Optimal value')\n",
    "plt.ylabel(r'$V^{\\pi}$', fontsize=17)\n",
    "plt.xlabel('Number of updates', fontsize=17)\n",
    "plt.xticks(range(len(root_values)), range(len(root_values)), fontsize=14, rotation=60)\n",
    "plt.yticks([0, 0.5, 1, 1.5, 2], fontsize=14)\n",
    "\n",
    "plt.xlim(0, len(qval_history)-1)\n",
    "plt.ylim(0, v_full+0.1)\n",
    "plt.legend(prop={'size':13})\n",
    "# plt.savefig(os.path.join(save_path, 'root_values.svg'), transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea050a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in enumerate(np.diff(root_values)):\n",
    "    print(idx+1, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e99b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "q0  = 1.5\n",
    "q1s = np.linspace(0, q0, 151)\n",
    "\n",
    "betas = [0.1, 0.5, 1, 4, 8]\n",
    "\n",
    "plt.figure(figsize=(16, 7))\n",
    "plt.subplot(121)\n",
    "\n",
    "for beta in betas:\n",
    "    tmp = []\n",
    "    for q1 in q1s:\n",
    "        qs   = np.array([q0, q1])\n",
    "        tmp += [np.dot(policy(qs, temp=beta), qs)]\n",
    "    plt.plot(tmp, label=r'$\\beta=%.2f$'%beta)\n",
    "plt.axhline(q0, c='k', label='Q-value for arm 1')\n",
    "plt.legend()\n",
    "plt.ylabel(r'$V^{\\pi}$', fontsize=16)\n",
    "plt.xlabel('Q-value for arm 2', fontsize=16)\n",
    "plt.xticks(range(0, len(q1s), 10), [np.round(q1s[i], 2) for i in range(0, len(q1s), 10)], rotation=60)\n",
    "\n",
    "plt.subplot(122)\n",
    "q0  = 4\n",
    "q1s = np.linspace(0, q0, 41)\n",
    "for beta in betas:\n",
    "    tmp = []\n",
    "    for q1 in q1s:\n",
    "        qs   = np.array([q0, q1])\n",
    "        tmp += [np.dot(policy(qs, temp=beta), qs)]\n",
    "    plt.plot(tmp, label=r'$\\beta=%.2f$'%beta)\n",
    "plt.axhline(q0, c='k', label='Q-value for arm 1')\n",
    "plt.legend()\n",
    "plt.ylabel(r'$V^{\\pi}$', fontsize=16)\n",
    "plt.xlabel('Q-value for arm 2', fontsize=16)\n",
    "plt.xticks(range(0, len(q1s), 10), [np.round(q1s[i], 2) for i in range(0, len(q1s), 10)], rotation=60)\n",
    "\n",
    "# save_path = '/home/georgy/Documents/Dayan_lab/PhD/bandits/bandit/data'\n",
    "# plt.savefig(os.path.join(save_path, 'softmax.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b54974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "560.85px",
    "left": "1066px",
    "right": "20px",
    "top": "120px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
